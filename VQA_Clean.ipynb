{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VQA Clean.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_s8xssZs3-s"
      },
      "source": [
        "# Installing packages\n",
        "Running this cell will download the Easy-VQA dataset which can be accessed later\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okwv-tYLs2-P",
        "outputId": "36570b2a-fe2d-401f-d9db-9f1a1018baa5"
      },
      "source": [
        "!pip install easy-vqa"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting easy-vqa\n",
            "  Downloading easy_vqa-1.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |                                | 10 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |▏                               | 20 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |▎                               | 30 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |▍                               | 40 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |▌                               | 51 kB 37.3 MB/s eta 0:00:01\r\u001b[K     |▋                               | 61 kB 35.2 MB/s eta 0:00:01\r\u001b[K     |▊                               | 71 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |▉                               | 81 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |█                               | 92 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 102 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 112 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 122 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 133 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 143 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 153 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 163 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 174 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 184 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 194 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 204 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 215 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 225 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 235 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 245 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 256 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 266 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 276 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 286 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 296 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 307 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 317 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 327 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 337 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 348 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 358 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 368 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 378 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 389 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 399 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 409 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 419 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 430 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 440 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 450 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 460 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 471 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 481 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 491 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 501 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 512 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 522 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 532 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 542 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 552 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 563 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 573 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 583 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 593 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 604 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 614 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 624 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 634 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 645 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 655 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 665 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 675 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 686 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 696 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 706 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 716 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 727 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 737 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 747 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 757 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 768 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 778 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 788 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 798 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 808 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 819 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 829 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 839 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 849 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 860 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 870 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 880 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 890 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 901 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 911 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 921 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 931 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 942 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 952 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 962 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 972 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 983 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 993 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 1.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 1.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 1.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 1.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 1.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 1.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 1.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 1.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 1.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 1.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 1.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 1.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 1.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 1.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 1.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 1.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 1.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 1.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 1.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 1.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 1.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 1.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 1.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 2.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 2.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 2.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 2.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 2.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 2.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 2.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 2.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 2.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 2.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 2.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 2.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 2.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 2.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 2.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 2.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 2.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 2.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 2.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 2.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 2.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 2.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 2.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 2.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 2.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 2.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 2.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 2.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 2.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 2.3 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 2.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 2.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 2.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 2.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 2.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 2.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 2.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 2.4 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 2.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 2.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 2.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 2.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 2.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 2.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.5 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 2.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 2.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 2.6 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 2.7 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.8 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.9 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 3.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 3.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 3.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 3.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 3.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 3.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 3.0 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 3.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 3.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 3.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 3.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 3.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 3.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 3.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 3.1 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 3.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 3.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 3.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 3.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 3.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.2 MB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.2 MB 34.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: easy-vqa\n",
            "Successfully installed easy-vqa-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJmyzM85s9Pc"
      },
      "source": [
        "# Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRulP202nQyv"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence \n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image \n",
        "from easy_vqa import get_train_image_paths, get_test_image_paths\n",
        "from easy_vqa import get_train_questions, get_test_questions\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZUd7OPWtb6Z"
      },
      "source": [
        "Loading the spacy model for tokenizing the question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1t4yfaBANUe"
      },
      "source": [
        "spacy_eng = spacy.load(\"en\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fl-g1kutmZn"
      },
      "source": [
        "# Dataloading and Vocabulary building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woASfnDqtrz-"
      },
      "source": [
        "This class will be used to make vocabulary according to the words in the question. After building the vocabulary, the words in the sentences are replaced by their correspoding index from the vocab dictionary. The words that are present in the vocabulary are those which appear above a particular frequency, this frequency is an argument of the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJoTtR_nBbuE"
      },
      "source": [
        "class Vocabulary:\n",
        "  def __init__(self, freq_threshold):\n",
        "    self.itos = {0:\"<PAD>\", 1:\"<SOS>\" , 2:\"<EOS>\" , 3:\"<UNK>\", 4:\"?\"} #itos = index to string\n",
        "    self.stoi = {\"<PAD>\":0 ,\"<SOS>\":1 ,\"<EOS>\":2 ,\"<UNK>\":3,\"?\":4 } #stoi = string to index\n",
        "    self.freq_threshold = freq_threshold\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.itos)\n",
        "\n",
        "  def tokenizer_eng(self,text):\n",
        "    lis = []\n",
        "    for tok in text.split():\n",
        "      if tok[-1]==\"?\":\n",
        "        lis.append(tok[0:-1])\n",
        "      else:\n",
        "        lis.append(tok)\n",
        "    return lis\n",
        "\n",
        "  def build_vocabulary(self, sentence_list):\n",
        "    frequencies = {}\n",
        "    idx = 5\n",
        "\n",
        "    for sentence in sentence_list:\n",
        "      for word in sentence.split():\n",
        "        if word[-1]==\"?\":\n",
        "          word = word[0:-1]\n",
        "        if word not in frequencies:\n",
        "          frequencies[word]=1\n",
        "        else:\n",
        "          frequencies[word]+=1\n",
        "        if frequencies[word] == self.freq_threshold:\n",
        "          self.stoi[word] = idx\n",
        "          self.itos[idx] = word\n",
        "          idx+=1\n",
        "\n",
        "  def numericalize(self, text):\n",
        "    tokenized_text = self.tokenizer_eng(text)\n",
        "    liss = []\n",
        "    for token in tokenized_text:\n",
        "      liss.append(self.stoi[token])\n",
        "    else:\n",
        "      liss.append(self.stoi[\"<UNK>\"])\n",
        "    return liss"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bfHQ0vLwAFS"
      },
      "source": [
        "This class is the Dataloader for the model. The questions, answer and images are achieved from the `easy-VQA` package that we installed before. For more information on the package please refer the following link: [easy-vqa](https://pypi.org/project/easy-vqa/) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaK_5FI5Exst"
      },
      "source": [
        "class VQADataset(Dataset):\n",
        "  def __init__(self, vocab, image_path, transforms=None, freq_threshold=1, train=True):\n",
        "    self.image_path = image_path\n",
        "    self.freq_threshold = freq_threshold\n",
        "    self.transforms = transforms\n",
        "\n",
        "    #get questions and answers\n",
        "    if train:\n",
        "      questions, answers, ids = get_train_questions()\n",
        "    else:\n",
        "      questions, answers, ids = get_test_questions()\n",
        "    self.image_ids = ids\n",
        "    self.questions = questions\n",
        "    self.answers = answers\n",
        "\n",
        "    #initialize vocab and build it\n",
        "    if train:  \n",
        "      self.vocab = Vocabulary(self.freq_threshold)\n",
        "      self.vocab.build_vocabulary(questions)\n",
        "    else:\n",
        "      self.vocab = Vocabulary(self.freq_threshold)\n",
        "      self.vocab.stoi = vocab\n",
        "      itos={}\n",
        "      for i in list(vocab.keys()):\n",
        "        itos[vocab[i]]=i\n",
        "      self.vocab.itos=itos\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.questions)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_id = self.image_ids[index]\n",
        "    image_path = self.image_path[img_id]\n",
        "    \n",
        "    image = Image.open(image_path)\n",
        "    image = np.array(image)\n",
        "    image = torch.Tensor(image)\n",
        "\n",
        "    normalised_question = [self.vocab.stoi[\"<SOS>\"]]\n",
        "    normalised_question += self.vocab.numericalize(self.questions[index])\n",
        "    normalised_question.append(self.vocab.stoi[\"<EOS>\"])\n",
        "    ans = self.answers[index]\n",
        "    return {'img':image, 'question':torch.Tensor(normalised_question), 'answer':ans}"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPgBDqi0xtyb"
      },
      "source": [
        "The Class is used for bunching the examples together for forming batched"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEaAg50PL9wp"
      },
      "source": [
        "class MyCollate:\n",
        "  def __init__(self, pad_idx):\n",
        "    self.pad_idx = pad_idx\n",
        "\n",
        "  def __call__(self, batch):\n",
        "    imgs=[]\n",
        "    for i in batch:\n",
        "      imgs.append(i[\"img\"].unsqueeze(0))\n",
        "    imgs = torch.cat(imgs, dim=0)\n",
        "\n",
        "    question = []\n",
        "    for i in batch:\n",
        "      question.append(i['question'])\n",
        "    question = pad_sequence(question, batch_first=True, padding_value=self.pad_idx)\n",
        "\n",
        "    answer = []\n",
        "    for i in batch:\n",
        "      answer.append(i['answer'])\n",
        "\n",
        "    return imgs, question, answer"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1zwX7vLx64P"
      },
      "source": [
        "# Creating a train-dataloader and validation data-loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3zZA7DQPo93"
      },
      "source": [
        "train_questions, train_answers, train_image_ids = get_train_questions()\n",
        "test_questions, test_answers, test_image_ids = get_test_questions()\n",
        "\n",
        "train_image_paths = get_train_image_paths()\n",
        "test_image_paths = get_test_image_paths()\n",
        "\n",
        "def get_loader(\n",
        "    vocab=None,\n",
        "    image_path=train_image_paths ,\n",
        "    ques_ans_id=get_train_questions, \n",
        "    transforms=None, \n",
        "    freq_threshold=1,\n",
        "    batch_size = 32,\n",
        "    shuffle = True,\n",
        "    train_flag=True\n",
        "):\n",
        "  dataset = VQADataset(vocab,image_path,train=train_flag)\n",
        "  pad_idx = dataset.vocab.stoi[\"<PAD>\"]\n",
        "  # print(dataset.vocab.stoi)\n",
        "  loader = DataLoader(dataset=dataset, \n",
        "                      batch_size=batch_size, \n",
        "                      shuffle=shuffle,\n",
        "                      collate_fn=MyCollate(pad_idx=pad_idx))\n",
        "  return loader, pad_idx, dataset.vocab.stoi\n",
        "\n",
        "trainloader, pad_idx, vocab = get_loader()\n",
        "testloader, _, _ = get_loader(vocab=vocab,image_path=test_image_paths, ques_ans_id=get_test_questions,train_flag=False)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1haY2dW01Pq"
      },
      "source": [
        "# Defining the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC0wd3LP1Bfw"
      },
      "source": [
        "This is the Image encoder. CConvolutional neural network is used for extracting image features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fzUnvReZ-X8"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()       \n",
        "    self.l1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3,out_channels=10, kernel_size=5),  #[(W−K+2P)/S]+1, W=64, K=5, P=0, S=1\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2)\n",
        "    )\n",
        "\n",
        "    self.l2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=10,out_channels=20, kernel_size=5),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2)\n",
        "    )\n",
        "\n",
        "    self.l3 = nn.Sequential(\n",
        "        nn.Linear(20*13*13,1000), \n",
        "        nn.ReLU(),\n",
        "        nn.Linear(1000,512)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.l1(x)\n",
        "    x = self.l2(x)\n",
        "    x = x.flatten(1)\n",
        "    x = self.l3(x)\n",
        "    return x"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU9zsRWx1ODJ"
      },
      "source": [
        "This is the Text encoder. LSTM is used as a text encoder to convert the text into a fixed sized embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khTVG_Mkl0QQ"
      },
      "source": [
        "class WordEncoding(nn.Module):\n",
        "  def __init__(self, vocab, embed_dim, hidden_dim):\n",
        "    super().__init__()\n",
        "    self.vocab_dim = len(vocab)\n",
        "    self.embed = nn.Embedding(self.vocab_dim, embed_dim)\n",
        "    self.seqseq = nn.LSTM(embed_dim, hidden_dim,  batch_first=True)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.embed(x)\n",
        "    output, a = self.seqseq(x)\n",
        "    hn, cn = a # hn = [1, batch, hidden_dim]\n",
        "    hn = hn.permute(1,0,2)\n",
        "    cn = cn.permute(1,0,2)\n",
        "    return (hn, cn)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhoLJsEcMPDo"
      },
      "source": [
        "This class combines the features from the image and text encoder and passes it through a multilayer perceptron to finally predict answer from a set of answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwYytO-YltGF",
        "outputId": "ef5251b5-2a59-45d8-85a6-768bed3d0850"
      },
      "source": [
        "class Combined(nn.Module):\n",
        "  def __init__(self, conv_class, seq, hidden_size,op_size):\n",
        "    super().__init__()\n",
        "    self.conv1 = conv_class\n",
        "    self.seq = seq\n",
        "    self.opLayer1 = nn.Linear(2*hidden_size,hidden_size)\n",
        "    self.opLayer2 = nn.Linear(hidden_size, op_size)\n",
        "  \n",
        "  def forward(self, image, text):\n",
        "    x1 = self.conv1(image)\n",
        "    # x1 = x1.view(x1.shape[0], x1.shape[1],-1)\n",
        "    xh2, xc2 = self.seq(text)    \n",
        "    xh2 = xh2.view(xh2.shape[0] ,xh2.shape[1],-1)\n",
        "    xc2 = xc2.view(xc2.shape[0] ,xc2.shape[1],-1)\n",
        "    x2 = torch.cat((xh2,xc2),dim=-1).squeeze(1)\n",
        "    x = torch.cat((x1,x2),dim=-1)\n",
        "    x = self.opLayer1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.opLayer2(x)\n",
        "    return x\n",
        "\n",
        "device='cuda'\n",
        "conv = ConvNet()\n",
        "rnn = WordEncoding(vocab, 128, 256)\n",
        "\n",
        "stud = Combined(conv, rnn, 512, 13).to(device)\n",
        "print(stud)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Combined(\n",
            "  (conv1): ConvNet(\n",
            "    (l1): Sequential(\n",
            "      (0): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (l2): Sequential(\n",
            "      (0): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (l3): Sequential(\n",
            "      (0): Linear(in_features=3380, out_features=1000, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=1000, out_features=512, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (seq): WordEncoding(\n",
            "    (embed): Embedding(31, 128)\n",
            "    (seqseq): LSTM(128, 256, batch_first=True)\n",
            "  )\n",
            "  (opLayer1): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (opLayer2): Linear(in_features=512, out_features=13, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjhQeE6qObvP"
      },
      "source": [
        "Defining the loss function, Optimizer and scheduler for changing the learning rate if loss increases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxQ1YNH4lfDb"
      },
      "source": [
        "optimizer = torch.optim.Adam(stud.parameters(),lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1,verbose=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiqsP8ohOnyC"
      },
      "source": [
        "Defining the set of possible answers. The answer to each question is one of the keys present in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL1NYu4Xk7Hc"
      },
      "source": [
        "answers_dict = {'red': 0, 'black': 1, 'no': 2, 'gray': 3, 'circle': 4, 'rectangle': 5, 'brown': 6, 'teal': 7, 'blue': 8, 'yellow': 9, 'yes': 10, 'triangle': 11, 'green': 12}"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGA8PUL0PHLh"
      },
      "source": [
        "# Training and evaluation loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dctkb6WOqYIG"
      },
      "source": [
        "def train(model, loader, answers_dict, optimizer, criterion, EPOCHS):\n",
        "  model.train()\n",
        "  epoch_loss = []\n",
        "  for i in range(EPOCHS):\n",
        "    l = 0\n",
        "    for data in loader:\n",
        "      image = data[0] #shape : [batch, H, W, C]\n",
        "      question = data[1]\n",
        "      answer = data[2]\n",
        "      batch_size = image.shape[0]\n",
        "\n",
        "      image = image.to('cuda')\n",
        "      question = question.long().to('cuda')\n",
        "\n",
        "      image = image.permute(0,3,1,2)\n",
        "      ans_list = []\n",
        "      for i in answer:\n",
        "        ans_list.append(answers_dict[i])\n",
        "      \n",
        "      target = torch.Tensor(ans_list).long().to('cuda')\n",
        "      output = model(image, question)\n",
        "      output = output.view(batch_size,-1)\n",
        "      target = target.view(-1)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss = criterion(output, target)\n",
        "      l+=loss.item()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    l/=len(loader)\n",
        "    scheduler.step(l)\n",
        "    print(l)\n",
        "    epoch_loss.append(l)\n",
        "\n",
        "  return epoch_loss"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKA2b75UPUv8"
      },
      "source": [
        "def accuracy(model, loader, answers_dict, optimizer, criterion):\n",
        "  model.eval()\n",
        "  ssum=0\n",
        "  c=0\n",
        "  for data in loader:\n",
        "    image = data[0] #shape : [batch, H, W, C]\n",
        "    question = data[1]\n",
        "    answer = data[2]\n",
        "    batch_size = image.shape[0]\n",
        "    c+=batch_size\n",
        "\n",
        "    image = image.to('cuda')\n",
        "    question = question.long().to('cuda')\n",
        "\n",
        "    image = image.permute(0,3,1,2)\n",
        "    ans_list = []\n",
        "    for i in answer:\n",
        "      ans_list.append(answers_dict[i])\n",
        "    \n",
        "    target = torch.Tensor(ans_list).long().to('cuda')\n",
        "    output = model(image, question)\n",
        "    output = torch.softmax(output, dim=-1)\n",
        "    output = torch.argmax(output, dim=-1)\n",
        "    # output = output.view(batch_size,-1)\n",
        "    target = target.view(-1)\n",
        "    ssum += torch.sum(output==target)\n",
        "  print((ssum/c).item())\n",
        "  return ssum/c\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmz4-krgsqZG",
        "outputId": "8cdcb2b3-9dac-4b43-a86e-212e8db9e701"
      },
      "source": [
        "loss = train(stud, trainloader, answers_dict, optimizer, criterion, 20)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6267546789834946\n",
            "0.389653689034938\n",
            "0.2839740755323747\n",
            "0.14928259962094734\n",
            "0.14494674957811424\n",
            "0.11155260835613423\n",
            "0.09678193214245197\n",
            "0.07189665013486429\n",
            "0.17674774239646737\n",
            "Epoch    10: reducing learning rate of group 0 to 1.0000e-04.\n",
            "0.16339041014158692\n",
            "0.12863263903310443\n",
            "Epoch    12: reducing learning rate of group 0 to 1.0000e-05.\n",
            "0.12136229231719439\n",
            "0.11969359834048926\n",
            "Epoch    14: reducing learning rate of group 0 to 1.0000e-06.\n",
            "0.1194456767579311\n",
            "0.11931264573817087\n",
            "Epoch    16: reducing learning rate of group 0 to 1.0000e-07.\n",
            "0.11929793079888597\n",
            "0.11924879336458638\n",
            "Epoch    18: reducing learning rate of group 0 to 1.0000e-08.\n",
            "0.1193813439215413\n",
            "0.11926313190376653\n",
            "0.11924208179895006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R28YkLa7jdvj",
        "outputId": "54da892a-188e-4095-fdd9-b62b918a0f16"
      },
      "source": [
        "train_accuracy = accuracy(stud, trainloader, answers_dict, optimizer, criterion)\n",
        "test_accuracy = accuracy(stud, testloader, answers_dict, optimizer, criterion)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9112637639045715\n",
            "0.8760467171669006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaqOF8CidyBO"
      },
      "source": [
        "Visualization of a question-image pair given as input "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "JP_rZBYos4S4",
        "outputId": "639a7bbc-cc9c-4f0b-bd91-c601bce770a6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "words = list(answers_dict.keys())\n",
        "nums = list(answers_dict.values())\n",
        "stud.eval()\n",
        "with torch.no_grad():\n",
        "  image_path = test_image_paths[10]\n",
        "  image = Image.open(image_path)\n",
        "  # image.show()\n",
        "  image = np.array(image)\n",
        "  plt.imshow(image)\n",
        "  image = torch.Tensor(image)\n",
        "  image = image.view(1,image.shape[0],image.shape[1],image.shape[2])\n",
        "  image = image.permute(0,3,1,2).to(device)\n",
        "  # print(image.shape)\n",
        "  q = 'what shape is present'\n",
        "  ques=[]\n",
        "  for i in q.split():\n",
        "    ques.append(vocab[i])\n",
        "\n",
        "  input_question = torch.Tensor(ques).long()\n",
        "  \n",
        "  # print(type(temp))\n",
        "  input_question = input_question.view(1,-1).to(device)\n",
        "  # print(input_question.shape)\n",
        "  op = stud.forward(image, input_question)\n",
        "  op = F.softmax(op,-1)\n",
        "  a = torch.argmax(op)\n",
        "  print(\"Question :\",q)\n",
        "  print(\"My answer to the question is : \"+str(words[a]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question : what shape is present\n",
            "My answer to the question is : circle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}